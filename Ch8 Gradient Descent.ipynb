{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in data science you are trying to solve some sort of optimization problem, and often you will have to solve them from scratch. Our approach to these problems is *gradient descent*, which lends itself pretty well to a from-scratch treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Idea Behind Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Suppose we have some funcion **f** that takes as input a vector of real numbers and outputs a single real number. Pne simple such function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sum_of_squares(v):\n",
    "    \"\"\"computes the sum of squared elemets in v\"\"\"\n",
    "    return sum(v_i ** 2 for v_i in v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Frequently we will need to maximize or minimize such functions. That is, we need to find the input **v** that produces the largest possible value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For functions like the one we are working on, the *gradient* (this is the vector of partial derivatives), gives the input direcction in which the function most quickly increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One apporach to maximizing a functino is to pick a random starting point, compute the gradient, take a small step in the direction of the gradient( ie the direction that causes the function to increase the most), and repeat with the new starting point. Similarly, you can try to minimize a function by taking small steps in the *opposite* direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* If a function has a unique global minimum, this procedure is likely to find it. If a function has multiple local minima, this procedure might \"find\" the worng one of them, in which case you might rerun the procedure from a variety of starting points. If a function has no minimum, thin it's possible the procedure might go on forever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Estimating the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If **f** if a function of one variable, its derivative at a point **x**, measures how **f(x)** changes when we make a small change to **x**. It is defined as the limit of difference quotients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def difference_quotient(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "#as h approches 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The derivative is the slope of the tangent line at **(x, f(x))**, while the difference quotient is the slope of the not-quite-tangent line that runs through **(x + h, f(x + h))**. As *h* gets smaller and smaller, the not-quite-tangent line gets closer and closer to the tangent line. Here is an approximate photo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='gradient.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a lot of functions it is pretty simple to calculate the derivative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
